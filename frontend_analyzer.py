#!/usr/bin/env python3
"""
Frontend Project Dependency Analyzer
Analyzes frontend project dependencies and generates structured reports.
"""

import os
import re
import json
from pathlib import Path
from typing import Dict, List, Set, Optional, Union, DefaultDict, Tuple, Any
from dataclasses import dataclass, field
from rich.console import Console
from rich.tree import Tree
from collections import defaultdict
import fnmatch
from functools import lru_cache
import hashlib
from datetime import datetime
import argparse

@dataclass
class SearchIndex:
    """File search index"""
    file_index: Dict[str, Set[str]] = field(default_factory=lambda: defaultdict(set))  # æ–‡ä»¶å -> è·¯å¾„é›†åˆ
    import_index: Dict[str, Set[str]] = field(default_factory=lambda: defaultdict(set))  # å¯¼å…¥å -> æ–‡ä»¶è·¯å¾„é›†åˆ
    extension_index: Dict[str, Set[str]] = field(default_factory=lambda: defaultdict(set))  # æ‰©å±•å -> æ–‡ä»¶è·¯å¾„é›†åˆ

@dataclass
class Config:
    """Configuration for the analyzer"""
    project_path: Path
    alias_mappings: Dict[str, str]
    ignore_patterns: Set[str]
    analyze_mode: str = "deep"  # 'deep' or 'shallow'
    max_depth: int = 5
    index_extensions: Dict[str, Dict[str, Union[List[str], List[str]]]] = field(default_factory=lambda: {
        "vue": {
            "extensions": [".vue"],
            "patterns": [
                r'import\s+(?:{[^}]*}|\*\s+as\s+\w+|\w+)\s+from\s+[\'"]([^\'"]+)[\'"]',
                r'require\([\'"]([^\'"]+)[\'"]\)',
                r'import\([\'"]([^\'"]+)[\'"]\)',
                r'import\s+type\s+{[^}]*}\s+from\s+[\'"]([^\'"]+)[\'"]'
            ]
        },
        "typescript": {
            "extensions": [".ts", ".tsx"],
            "patterns": [
                r'import\s+(?:{[^}]*}|\*\s+as\s+\w+|\w+)\s+from\s+[\'"]([^\'"]+)[\'"]',
                r'import\s+type\s+{[^}]*}\s+from\s+[\'"]([^\'"]+)[\'"]'
            ]
        },
        "javascript": {
            "extensions": [".js", ".jsx"],
            "patterns": [
                r'import\s+(?:{[^}]*}|\*\s+as\s+\w+|\w+)\s+from\s+[\'"]([^\'"]+)[\'"]',
                r'require\([\'"]([^\'"]+)[\'"]\)'
            ]
        }
    })

    @staticmethod
    def default_index_extensions():
        """Default index extensions configuration"""
        return {
            "vue": {
                "extensions": [".vue"],
                "patterns": [
                    r'import\s+(?:{[^}]*}|\*\s+as\s+\w+|\w+)\s+from\s+[\'"]([^\'"]+)[\'"]',
                    r'require\([\'"]([^\'"]+)[\'"]\)',
                    r'import\([\'"]([^\'"]+)[\'"]\)',
                    r'import\s+type\s+{[^}]*}\s+from\s+[\'"]([^\'"]+)[\'"]'
                ]
            },
            "typescript": {
                "extensions": [".ts", ".tsx"],
                "patterns": [
                    r'import\s+(?:{[^}]*}|\*\s+as\s+\w+|\w+)\s+from\s+[\'"]([^\'"]+)[\'"]',
                    r'import\s+type\s+{[^}]*}\s+from\s+[\'"]([^\'"]+)[\'"]'
                ]
            },
            "javascript": {
                "extensions": [".js", ".jsx"],
                "patterns": [
                    r'import\s+(?:{[^}]*}|\*\s+as\s+\w+|\w+)\s+from\s+[\'"]([^\'"]+)[\'"]',
                    r'require\([\'"]([^\'"]+)[\'"]\)'
                ]
            }
        }

    @classmethod
    def load(cls, config_path: Union[str, Path] = "config.json") -> 'Config':
        """Load configuration from a JSON file"""
        try:
            with open(config_path, 'r') as f:
                data = json.load(f)
                return cls(
                    project_path=Path(os.path.expanduser(data['project_path'])),
                    alias_mappings=data.get('alias_mappings', {}),
                    ignore_patterns=set(data.get('ignore_patterns', [])),
                    analyze_mode=data.get('analyze_mode', 'deep'),
                    max_depth=data.get('max_depth', 5),
                    index_extensions=data.get('index_extensions', cls.default_index_extensions())
                )
        except FileNotFoundError:
            console = Console()
            console.print(f"[yellow]Warning: Config file {config_path} not found. Using default configuration.[/yellow]")
            return cls(
                project_path=Path.cwd(),
                alias_mappings={},
                ignore_patterns={'node_modules', 'dist', 'build', '.git', '__pycache__', '.DS_Store', '.history'},
                analyze_mode='deep',
                max_depth=5
            )

@dataclass
class DependencyInfo:
    """Stores dependency information for a file"""
    components: Dict[str, 'DependencyInfo'] = field(default_factory=dict)  # Changed from Set to Dict for nested deps
    hooks: Set[str] = field(default_factory=set)
    utils: Set[str] = field(default_factory=set)
    types: Set[str] = field(default_factory=set)
    styles: Set[str] = field(default_factory=set)
    external: Set[str] = field(default_factory=set)
    api: Set[str] = field(default_factory=set)
    depth: int = 0
    parent: Optional[str] = None

@dataclass
class FileInfo:
    """Stores file information and its dependencies"""
    path: Path
    file_type: str
    dependencies: DependencyInfo = field(default_factory=DependencyInfo)
    analyzed: bool = False

@dataclass
class MerkleNode:
    """Merkleæ ‘èŠ‚ç‚¹"""
    hash: str
    type: str  # 'file', 'component', 'api', 'hook', 'util', 'external'
    name: str
    children: List['MerkleNode'] = field(default_factory=list)
    content: Optional[str] = None
    metadata: Dict[str, Any] = field(default_factory=dict)  # å­˜å‚¨é¢å¤–çš„å…ƒæ•°æ®
    imports: List[str] = field(default_factory=list)  # å­˜å‚¨å¯¼å…¥è¯­å¥
    exports: List[str] = field(default_factory=list)  # å­˜å‚¨å¯¼å‡ºå†…å®¹
    dependencies_count: Dict[str, int] = field(default_factory=lambda: defaultdict(int))  # å„ç±»å‹ä¾èµ–æ•°é‡ç»Ÿè®¡

class DependencyMerkleTree:
    """ä¾èµ–å…³ç³»çš„Merkleæ ‘å®ç°"""
    
    def __init__(self):
        self.nodes: Dict[str, MerkleNode] = {}
    
    def _calculate_hash(self, content: str) -> str:
        """è®¡ç®—å†…å®¹çš„å“ˆå¸Œå€¼"""
        return hashlib.sha256(content.encode()).hexdigest()[:8]  # ä½¿ç”¨çŸ­å“ˆå¸Œä»¥æé«˜å¯è¯»æ€§
    
    def _extract_file_info(self, file_path: Path) -> Dict[str, Any]:
        """æå–æ–‡ä»¶çš„è¯¦ç»†ä¿¡æ¯"""
        try:
            content = file_path.read_text(encoding='utf-8')
            
            # æå–å¯¼å…¥è¯­å¥
            imports = re.findall(r'import\s+.*?[\'"]([^\'"]+)[\'"]', content)
            
            # æå–å¯¼å‡ºè¯­å¥
            exports = re.findall(r'export\s+(?:default\s+)?(?:class|function|const|let|var)\s+(\w+)', content)
            
            # ç»Ÿè®¡ä»£ç è¡Œæ•°ï¼ˆæ’é™¤ç©ºè¡Œå’Œæ³¨é‡Šï¼‰
            lines = content.split('\n')
            code_lines = len([line for line in lines if line.strip() and not line.strip().startswith('//')])
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«ç‰¹å®šåŠŸèƒ½
            has_state_management = bool(re.search(r'useState|useReducer|createStore|Vuex|Pinia', content))
            has_routing = bool(re.search(r'useRouter|useRoute|Router|createRouter', content))
            has_api_calls = bool(re.search(r'fetch|axios|useQuery|useMutation', content))
            has_form_handling = bool(re.search(r'useForm|v-model|formData|handleSubmit', content))
            
            return {
                'imports': imports,
                'exports': exports,
                'code_lines': code_lines,
                'features': {
                    'state_management': has_state_management,
                    'routing': has_routing,
                    'api_calls': has_api_calls,
                    'form_handling': has_form_handling
                }
            }
        except Exception:
            return {}
    
    def _create_node(self, name: str, type: str, content: Optional[str] = None, file_path: Optional[Path] = None) -> MerkleNode:
        """åˆ›å»ºæˆ–è·å–èŠ‚ç‚¹"""
        if name in self.nodes:
            return self.nodes[name]
            
        node_content = content or name
        node_hash = self._calculate_hash(f"{type}:{node_content}")
        
        # åˆå§‹åŒ–èŠ‚ç‚¹
        node = MerkleNode(
            hash=node_hash,
            type=type,
            name=name,
            content=content,
            metadata={},
            imports=[],
            exports=[],
            dependencies_count=defaultdict(int)
        )
        
        # å¦‚æœæä¾›äº†æ–‡ä»¶è·¯å¾„ï¼Œæå–æ›´å¤šä¿¡æ¯
        if file_path and file_path.exists():
            file_info = self._extract_file_info(file_path)
            node.metadata.update(file_info)
            node.imports.extend(file_info.get('imports', []))
            node.exports.extend(file_info.get('exports', []))
        
        self.nodes[name] = node
        return node
    
    def build_from_dependencies(self, deps: DependencyInfo, file_path: str) -> MerkleNode:
        """ä»ä¾èµ–ä¿¡æ¯æ„å»ºMerkleæ ‘"""
        root = self._create_node(file_path, 'file', file_path=Path(file_path))
        
        # ç»Ÿè®¡ä¾èµ–æ•°é‡
        root.dependencies_count.update({
            'components': len(deps.components),
            'api': len(deps.api),
            'hooks': len(deps.hooks),
            'utils': len(deps.utils),
            'external': len(deps.external)
        })
        
        # æ·»åŠ ç»„ä»¶ä¾èµ–
        for comp_name in deps.components:
            comp_node = self._create_node(comp_name, 'component', file_path=Path(comp_name))
            root.children.append(comp_node)
        
        # æ·»åŠ APIä¾èµ–
        for api_name in deps.api:
            api_node = self._create_node(api_name, 'api', file_path=Path(api_name))
            root.children.append(api_node)
        
        # æ·»åŠ Hooksä¾èµ–
        for hook_name in deps.hooks:
            hook_node = self._create_node(hook_name, 'hook', file_path=Path(hook_name))
            root.children.append(hook_node)
        
        # æ·»åŠ å·¥å…·ä¾èµ–
        for util_name in deps.utils:
            util_node = self._create_node(util_name, 'util', file_path=Path(util_name))
            root.children.append(util_node)
        
        # æ·»åŠ å¤–éƒ¨ä¾èµ–
        for ext_name in deps.external:
            ext_node = self._create_node(ext_name, 'external')
            root.children.append(ext_node)
        
        return root
    
    def generate_ai_readable_format(self, root: MerkleNode, indent: int = 0) -> str:
        """ç”ŸæˆAIå‹å¥½çš„å¯è¯»æ ¼å¼"""
        result = []
        prefix = "  " * indent
        
        # æ·»åŠ èŠ‚ç‚¹åŸºæœ¬ä¿¡æ¯
        node_info = f"{prefix}[{root.type}:{root.hash}] {root.name}"
        result.append(node_info)
        
        # æ·»åŠ å…ƒæ•°æ®ä¿¡æ¯
        if root.metadata:
            meta_prefix = "  " * (indent + 1)
            if 'code_lines' in root.metadata:
                result.append(f"{meta_prefix}ğŸ“Š ä»£ç è¡Œæ•°: {root.metadata['code_lines']}")
            
            if 'features' in root.metadata:
                features = root.metadata['features']
                feature_icons = {
                    'state_management': 'ğŸ”„ çŠ¶æ€ç®¡ç†',
                    'routing': 'ğŸ›£ï¸ è·¯ç”±å¤„ç†',
                    'api_calls': 'ğŸŒ APIè°ƒç”¨',
                    'form_handling': 'ğŸ“ è¡¨å•å¤„ç†'
                }
                active_features = [f"{icon}" for key, icon in feature_icons.items() if features.get(key)]
                if active_features:
                    result.append(f"{meta_prefix}âœ¨ åŠŸèƒ½ç‰¹æ€§: {' '.join(active_features)}")
        
        # æ·»åŠ ä¾èµ–ç»Ÿè®¡
        if root.dependencies_count:
            stats_prefix = "  " * (indent + 1)
            stats = [f"{k}: {v}" for k, v in root.dependencies_count.items() if v > 0]
            if stats:
                result.append(f"{stats_prefix}ğŸ“ˆ ä¾èµ–ç»Ÿè®¡: {', '.join(stats)}")
        
        # æ·»åŠ å¯¼å…¥å¯¼å‡ºä¿¡æ¯
        if root.imports:
            imports_prefix = "  " * (indent + 1)
            result.append(f"{imports_prefix}ğŸ“¥ å¯¼å…¥: {', '.join(root.imports[:3])}{'...' if len(root.imports) > 3 else ''}")
        if root.exports:
            exports_prefix = "  " * (indent + 1)
            result.append(f"{exports_prefix}ğŸ“¤ å¯¼å‡º: {', '.join(root.exports)}")
        
        # é€’å½’å¤„ç†å­èŠ‚ç‚¹
        for child in root.children:
            result.append(self.generate_ai_readable_format(child, indent + 1))
        
        return "\n".join(result)

    def export_report(self, root: MerkleNode, file_path: str, prompt: str = "", focus_points: List[str] = None) -> str:
        """å¯¼å‡ºåˆ†ææŠ¥å‘Šåˆ°æ–‡ä»¶"""
        content = []
        
        # æ·»åŠ åˆ†éš”çº¿
        content.append("-" * 20)
        
        # æ·»åŠ AIæç¤ºè¯
        if prompt:
            content.append(prompt)
            
        if focus_points:
            content.append("\né‡ç‚¹å…³æ³¨é¢†åŸŸ:")
            for point in focus_points:
                content.append(f"â€¢ {point}")
        
        # æ·»åŠ Merkleæ ‘åˆ†æ
        content.append("\nä»¥ä¸‹æ˜¯Merkleæ ‘åˆ†æ:\n")
        content.append("Merkleæ ‘åˆ†æ:")
        content.append(self.generate_ai_readable_format(root))
        
        # æ·»åŠ åº•éƒ¨åˆ†éš”çº¿
        content.append("-" * 20)
        
        return "\n".join(content)

class FrontendAnalyzer:
    def __init__(self, config: Config):
        self.config = config
        self.files: Dict[str, FileInfo] = {}
        self.dependency_graph: DefaultDict[str, Set[str]] = defaultdict(set)
        self.console = Console()
        self.search_index = SearchIndex()
        self.merkle_tree = DependencyMerkleTree()
        
        # åˆ›å»ºreportsç›®å½•
        self.reports_dir = Path("reports")
        self.reports_dir.mkdir(exist_ok=True)
        
        # åŠ è½½æç¤ºè¯é…ç½®
        self.prompts = self._load_prompts()
        
        # ä»é…ç½®æ–‡ä»¶åŠ è½½å¯¼å…¥æ¨¡å¼
        self.import_patterns = {}
        if hasattr(config, 'index_extensions'):
            for lang, lang_config in config.index_extensions.items():
                for pattern in lang_config['patterns']:
                    self.import_patterns[f"{lang}_{pattern[:10]}"] = pattern
        else:
            # é»˜è®¤çš„å¯¼å…¥æ¨¡å¼ä½œä¸ºåå¤‡
            self.import_patterns = {
                'es6': r'import\s+(?:{[^}]*}|\*\s+as\s+\w+|\w+)\s+from\s+[\'"]([^\'"]+)[\'"]',
                'require': r'require\([\'"]([^\'"]+)[\'"]\)',
                'dynamic': r'import\([\'"]([^\'"]+)[\'"]\)',
                'type': r'import\s+type\s+{[^}]*}\s+from\s+[\'"]([^\'"]+)[\'"]'
            }

    def _load_prompts(self) -> Dict:
        """åŠ è½½æç¤ºè¯é…ç½®"""
        try:
            with open('prompts.json', 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            self.console.print(f"[yellow]Warning: Failed to load prompts.json: {e}[/yellow]")
            return {"commit_types": {}}

    def generate_report(self, commit_type: str = "feat"):
        """ç”Ÿæˆå¹¶æ‰“å°åˆ†ææŠ¥å‘Š"""
        if not self.files:
            self.console.print("[yellow]è¿˜æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ–‡ä»¶å‘¢~[/yellow]")
            return
        
        # è·å–å¯¹åº”ç±»å‹çš„æç¤ºè¯
        prompt_config = self.prompts.get("commit_types", {}).get(commit_type, {})
        
        # è·å–åˆ†æçš„æ–‡ä»¶
        try:
            target_file = Path(self.config.project_path)
            if target_file.is_file():
                rel_path = target_file.relative_to(target_file.parent.parent.parent)
                
                # ç”ŸæˆMerkleæ ‘
                merkle_root = None
                for file_path, file_info in self.files.items():
                    if str(rel_path) in file_path:
                        merkle_root = self.merkle_tree.build_from_dependencies(file_info.dependencies, file_path)
                        break
                
                if merkle_root:
                    # å¯¼å‡ºæŠ¥å‘Šåˆ°æ–‡ä»¶
                    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                    file_name = target_file.name.replace('.', '_')
                    report_file = self.reports_dir / f"report_{timestamp}_{commit_type}_{file_name}.txt"
                    
                    report_content = self.merkle_tree.export_report(
                        merkle_root, 
                        str(target_file),
                        prompt_config.get('prompt', ''),
                        prompt_config.get('focus', [])
                    )
                    report_file.write_text(report_content, encoding='utf-8')
        
        except Exception as e:
            self.console.print(f"[red]æŠ±æ­‰ï¼Œå‡ºäº†ç‚¹å°é—®é¢˜: {e}[/red]")
            return

    def _should_ignore(self, path: Path) -> bool:
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥å¿½ç•¥è¯¥æ–‡ä»¶"""
        return any(part in self.config.ignore_patterns for part in path.parts)
    
    def _determine_file_type(self, file_path: Path) -> Optional[str]:
        """æ ¹æ®æ–‡ä»¶è·¯å¾„å’Œæ‰©å±•åç¡®å®šæ–‡ä»¶ç±»å‹"""
        suffix = file_path.suffix
        
        # ä»é…ç½®ä¸­è·å–æ–‡ä»¶ç±»å‹
        for lang, lang_config in self.config.index_extensions.items():
            if suffix in lang_config['extensions']:
                return lang
                
        return None
    
    def _extract_dependencies(self, content: str, deps: DependencyInfo):
        """ä»æ–‡ä»¶å†…å®¹ä¸­æå–æ‰€æœ‰ä¾èµ–"""
        for pattern_name, pattern in self.import_patterns.items():
            matches = re.finditer(pattern, content)
            for match in matches:
                import_path = match.group(1)
                self._categorize_dependency(import_path, deps)
    
    def _categorize_dependency(self, import_path: str, deps: DependencyInfo):
        """æ ¹æ®å¯¼å…¥è·¯å¾„å¯¹ä¾èµ–è¿›è¡Œåˆ†ç±»"""
        # å¤„ç†ä»¥ @ å¼€å¤´çš„åˆ«åå¯¼å…¥
        if import_path.startswith('@/'):
            parts = import_path.split('/')
            if len(parts) > 1:
                category = parts[1]  # è·å– @/ åçš„ç±»åˆ«
                if category == 'components':
                    deps.components[import_path] = DependencyInfo(depth=deps.depth + 1, parent=import_path)
                elif category == 'hooks':
                    deps.hooks.add(import_path)
                elif category == 'utils':
                    deps.utils.add(import_path)
                elif category == 'types':
                    deps.types.add(import_path)
                elif category == 'api':
                    deps.api.add(import_path)
                elif category.endswith(('.css', '.scss', '.less', '.sass')):
                    deps.styles.add(import_path)
                else:
                    # é»˜è®¤æ·»åŠ åˆ°å·¥å…·ç±»
                    deps.utils.add(import_path)
            return
        
        # å¤„ç†ç›¸å¯¹è·¯å¾„å’Œå…¶ä»–æƒ…å†µ
        if 'components' in import_path:
            deps.components[import_path] = DependencyInfo(depth=deps.depth + 1, parent=import_path)
        elif 'hooks' in import_path:
            deps.hooks.add(import_path)
        elif 'utils' in import_path:
            deps.utils.add(import_path)
        elif 'types' in import_path or import_path.endswith('.d.ts'):
            deps.types.add(import_path)
        elif 'api' in import_path:
            deps.api.add(import_path)
        elif import_path.endswith(('.css', '.scss', '.less', '.sass')):
            deps.styles.add(import_path)
        elif not any(import_path.startswith(p) for p in ['/', '.', '@']):
            deps.external.add(import_path)
        else:
            # é»˜è®¤æ·»åŠ åˆ°å·¥å…·ç±»
            deps.utils.add(import_path)
    
    def _process_file(self, file_path: Path, depth: int = 0):
        """å¤„ç†å•ä¸ªæ–‡ä»¶å¹¶æå–å…¶ä¾èµ–"""
        try:
            relative_path = file_path.relative_to(self.config.project_path.parent.parent.parent)
            if self._should_ignore(file_path):
                return
            
            file_type = self._determine_file_type(file_path)
            if not file_type:
                return
                
            file_info = FileInfo(path=relative_path, file_type=file_type)
            content = file_path.read_text(encoding='utf-8')
            
            deps = DependencyInfo(depth=depth)
            self._extract_dependencies(content, deps)
            file_info.dependencies = deps
            file_info.analyzed = True
            
            self.files[str(relative_path)] = file_info
            
        except Exception as e:
            self.console.print(f"[red]Error processing {file_path}: {e}[/red]")
    
    def analyze_file(self, file_path: Union[str, Path], depth: int = 0):
        """åˆ†æç‰¹å®šæ–‡ä»¶åŠå…¶ä¾èµ–"""
        if depth > self.config.max_depth:
            return
        
        file_path = Path(file_path)
        if not file_path.exists():
            self.console.print(f"[red]æŠ±æ­‰ï¼Œæ‰¾ä¸åˆ°æ–‡ä»¶: {file_path}[/red]")
            return
        
        # é™é»˜å¤„ç†æ–‡ä»¶
        self._process_file(file_path, depth)
        
        if self.config.analyze_mode == "deep":
            self._analyze_dependencies(file_path, depth + 1)
    
    def _analyze_dependencies(self, file_path: Path, depth: int):
        """é€’å½’åˆ†ææ–‡ä»¶çš„ä¾èµ–"""
        try:
            file_key = str(file_path.relative_to(self.config.project_path.parent.parent.parent))
        except ValueError:
            file_key = str(file_path)
            
        if file_key not in self.files:
            return
        
        file_info = self.files[file_key]
        deps = file_info.dependencies
        
        # åˆ†æç»„ä»¶ä¾èµ–
        for comp_path, comp_dep in deps.components.items():
            resolved_path = self._resolve_dependency_path(comp_path)
            if resolved_path:
                self.dependency_graph[file_key].add(str(resolved_path))
                if not self._is_analyzed(resolved_path):
                    self.analyze_file(resolved_path, depth)
        
        # åˆ†æå…¶ä»–ä¾èµ–ï¼ˆhooks, utilsç­‰ï¼‰
        for dep_set in [deps.hooks, deps.utils]:
            for dep_path in dep_set:
                resolved_path = self._resolve_dependency_path(dep_path)
                if resolved_path:
                    self.dependency_graph[file_key].add(str(resolved_path))
                    if not self._is_analyzed(resolved_path):
                        self.analyze_file(resolved_path, depth)
    
    def _is_analyzed(self, file_path: Path) -> bool:
        """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²ç»è¢«åˆ†æè¿‡"""
        try:
            relative_path = str(file_path.relative_to(self.config.project_path.parent.parent.parent))
            return relative_path in self.files and self.files[relative_path].analyzed
        except ValueError:
            return False
    
    def _resolve_dependency_path(self, import_path: str) -> Optional[Path]:
        """è§£æä¾èµ–è·¯å¾„"""
        project_root = self.config.project_path.parent.parent.parent
        current_dir = self.config.project_path.parent
        
        # 1. å¤„ç†ç›¸å¯¹è·¯å¾„
        if import_path.startswith('./') or import_path.startswith('../'):
            resolved_path = (current_dir / import_path).resolve()
            if resolved_path.exists():
                return resolved_path
            
            # å°è¯•æ·»åŠ ä¸åŒçš„æ‰©å±•å
            for ext in ['.tsx', '.jsx', '.ts', '.js', '.vue', '/index.tsx', '/index.jsx', '/index.ts', '/index.js', '/index.vue']:
                test_path = resolved_path.with_suffix(ext) if not ext.startswith('/') else Path(str(resolved_path) + ext)
                if test_path.exists():
                    return test_path
        
        # 2. å¤„ç†åˆ«åè·¯å¾„
        if import_path.startswith('@/'):
            # å¦‚æœé…ç½®ä¸­æœ‰ "@": "src" çš„æ˜ å°„
            if "@" in self.config.alias_mappings:
                # ç›´æ¥å°† @/ æ›¿æ¢ä¸º src/
                normalized_path = import_path.replace('@/', f"{self.config.alias_mappings['@']}/", 1)
                full_path = project_root / normalized_path
                
                # æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨
                if full_path.exists():
                    return full_path
                
                # å°è¯•ä¸åŒçš„æ‰©å±•å
                for ext in ['.tsx', '.jsx', '.ts', '.js', '.vue', '/index.tsx', '/index.jsx', '/index.ts', '/index.js', '/index.vue']:
                    test_path = full_path.with_suffix(ext) if not ext.startswith('/') else Path(str(full_path) + ext)
                    if test_path.exists():
                        return test_path
        
        # 3. æ£€æŸ¥å¯¼å…¥ç´¢å¼•
        if import_path in self.search_index.import_index:
            paths = self.search_index.import_index[import_path]
            if paths:
                return project_root / next(iter(paths))
        
        # 4. æ™ºèƒ½æŸ¥æ‰¾
        base_name = os.path.basename(import_path)
        if base_name:
            # ç§»é™¤å¯èƒ½çš„æ‰©å±•å
            base_name = os.path.splitext(base_name)[0]
            found_path = self._find_file(base_name, current_dir)
            if found_path:
                return found_path
        
        # 5. å°è¯•ä¸åŒçš„æ‰©å±•å
        base_path = project_root / import_path.lstrip('/')
        for ext in ['.tsx', '.jsx', '.ts', '.js', '.vue', '/index.tsx', '/index.jsx', '/index.ts', '/index.js', '/index.vue']:
            full_path = base_path.with_suffix(ext) if not ext.startswith('/') else Path(str(base_path) + ext)
            if full_path.exists():
                return full_path
            
            # é¢å¤–æ£€æŸ¥ç›¸å¯¹äºå½“å‰ç›®å½•çš„è·¯å¾„
            current_full_path = (current_dir / import_path).with_suffix(ext) if not ext.startswith('/') else Path(str(current_dir / import_path) + ext)
            if current_full_path.exists():
                return current_full_path
        
        return None
    
    def _find_file(self, name: str, current_dir: Optional[Path] = None) -> Optional[Path]:
        """æ™ºèƒ½æ–‡ä»¶æŸ¥æ‰¾"""
        project_root = self.config.project_path.parent.parent.parent
        
        # 1. æ£€æŸ¥ç´¢å¼•ä¸­çš„ç²¾ç¡®åŒ¹é…
        if name in self.search_index.file_index:
            paths = self.search_index.file_index[name]
            if len(paths) == 1:
                return project_root / next(iter(paths))
            elif current_dir:
                # å¦‚æœæœ‰å¤šä¸ªåŒ¹é…ï¼Œä¼˜å…ˆé€‰æ‹©ç¦»å½“å‰ç›®å½•æœ€è¿‘çš„
                return min(
                    (project_root / path for path in paths),
                    key=lambda p: len(set(p.parts) ^ set(current_dir.parts))
                )
        
        # 2. å°è¯•æ¨¡ç³ŠåŒ¹é…
        for pattern in [f"*{name}*", f"*{name}", f"{name}*"]:
            matches = set()
            for filename, paths in self.search_index.file_index.items():
                if fnmatch.fnmatch(filename.lower(), pattern.lower()):
                    matches.update(paths)
            
            if matches:
                if len(matches) == 1:
                    return project_root / next(iter(matches))
                elif current_dir:
                    return min(
                        (project_root / path for path in matches),
                        key=lambda p: len(set(p.parts) ^ set(current_dir.parts))
                    )
        
        # 3. åœ¨å½“å‰ç›®å½•ä¸­æœç´¢
        if current_dir:
            for file_path in current_dir.rglob(f"*{name}*"):
                if file_path.is_file() and not self._should_ignore(file_path):
                    return file_path
        
        return None

def display_menu(prompts: Dict) -> str:
    """æ˜¾ç¤ºäº¤äº’å¼èœå•"""
    console = Console()
    console.print("\n[bold magenta]âœ¨ æ¬¢è¿ä½¿ç”¨å‰ç«¯å°åŠ©æ‰‹ âœ¨[/bold magenta]")
    console.print("[bold magenta]è®©æˆ‘ä»¬ä¸€èµ·æ¥åˆ†æä»£ç å§~ [/bold magenta]\n")
    
    # æ˜¾ç¤ºæ‰€æœ‰é€‰é¡¹
    for i, (type_key, type_info) in enumerate(prompts['commit_types'].items(), 1):
        console.print(f"[green]{i}.[/green] {type_info['title']} [cyan]({type_key})[/cyan]")
    
    console.print("\n[yellow]è¯·é€‰æ‹©åˆ†æç±»å‹å“¦~ (è¾“å…¥æ•°å­—)[/yellow]")
    
    while True:
        try:
            choice = int(input("âœ ").strip())
            if 1 <= choice <= len(prompts['commit_types']):
                return list(prompts['commit_types'].keys())[choice - 1]
            else:
                console.print("[red]å“å‘€ï¼Œè¿™ä¸ªæ•°å­—ä¸å¯¹å‘¢ï¼Œè¯·é‡æ–°é€‰æ‹©~[/red]")
        except ValueError:
            console.print("[red]éœ€è¦è¾“å…¥æ•°å­—å•¦ï¼Œè®©æˆ‘ä»¬é‡æ–°æ¥è¿‡~[/red]")

def main():
    """Main entry point"""
    console = Console()
    
    try:
        config = Config.load()
        analyzer = FrontendAnalyzer(config)
        
        # åŠ è½½æç¤ºè¯é…ç½®
        try:
            with open('prompts.json', 'r', encoding='utf-8') as f:
                prompts = json.load(f)
        except Exception as e:
            console.print(f"[red]å“å‘€ï¼ŒåŠ è½½æç¤ºè¯é…ç½®å¤±è´¥äº†: {e}[/red]")
            return 1
        
        # æ˜¾ç¤ºèœå•å¹¶è·å–ç”¨æˆ·é€‰æ‹©
        commit_type = display_menu(prompts)
        
        # å¦‚æœæ˜¯å•æ–‡ä»¶åˆ†ææ¨¡å¼
        if Path(config.project_path).is_file():
            console.print("[yellow]ğŸ” å¼€å§‹åˆ†ææ–‡ä»¶å•¦...[/yellow]")
            analyzer.analyze_file(config.project_path)
        else:
            console.print("[yellow]ğŸ” æ­£åœ¨æ‰«æé¡¹ç›®ç›®å½•...[/yellow]")
            analyzer.analyze_file(config.project_path)
        
        console.print("\n[green]ğŸ¨ æ­£åœ¨ç”Ÿæˆåˆ†ææŠ¥å‘Š...[/green]")
        analyzer.generate_report(commit_type=commit_type)
        console.print("\n[bold green]âœ¨ åˆ†æå®Œæˆå•¦ï¼å¿«å»çœ‹çœ‹æŠ¥å‘Šå§~ âœ¨[/bold green]")
        
    except Exception as e:
        console.print(f"[red]æŠ±æ­‰ï¼Œå‡ºäº†ç‚¹å°é—®é¢˜: {e}[/red]")
        return 1
    
    return 0

if __name__ == "__main__":
    exit(main()) 